{
    "controller_name": "PPO Agent (deterministic)",
    "num_episodes": 1,
    "environment_params": {
        "episode_length": 5760,
        "time_step_seconds": 30,
        "heating_setpoint": 26.0,
        "cooling_setpoint": 28.0,
        "setpoint_pattern": "schedule",
        "reward_type": "balanced",
        "energy_weight": 1.0,
        "comfort_weight": 0.2,
        "random_start_time": false,
        "use_reward_shaping": true,
        "shaping_weight": 0.3
    },
    "episodes": [
        {
            "episode_id": 0,
            "total_reward": 4975.836505226838,
            "avg_reward": 0.8637105546305917,
            "episode_start_time_offset": 0.0,
            "comfort_metrics": {
                "ground_floor_avg_cold_violation": 0.026436173054493403,
                "ground_floor_avg_hot_violation": 0.018998745815144123,
                "ground_floor_max_violation": 4.461725492239122,
                "top_floor_avg_cold_violation": 0.0206934518013565,
                "top_floor_avg_hot_violation": 0.037655226382739146,
                "top_floor_max_violation": 3.679214527915221,
                "time_in_comfort_band_ground_pct": 86.70369727477868,
                "time_in_comfort_band_top_pct": 85.22825898281549
            },
            "energy_metrics": {
                "ground_light_hours": 4.891666666666667,
                "top_light_hours": 0.30833333333333335,
                "total_light_hours": 5.2,
                "ground_window_open_hours": 7.933333333333334,
                "top_window_open_hours": 35.65833333333333
            }
        }
    ],
    "overall_metrics": {
        "avg_total_reward": 4975.836505226838,
        "avg_ground_comfort_pct": 86.70369727477868,
        "avg_top_comfort_pct": 85.22825898281549,
        "avg_light_energy": 5.2,
        "avg_start_time_offset": 0.0
    }
}